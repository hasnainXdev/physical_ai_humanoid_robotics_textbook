<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module4-vla-robotics/introduction" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Introduction to LLM-Driven Robotics | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://physical-ai-humanoid-robotics-textb-tau.vercel.app/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://physical-ai-humanoid-robotics-textb-tau.vercel.app/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://physical-ai-humanoid-robotics-textb-tau.vercel.app/docs/module4-vla-robotics/introduction"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Introduction to LLM-Driven Robotics | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="The Convergence of Large Language Models and Robotics"><meta data-rh="true" property="og:description" content="The Convergence of Large Language Models and Robotics"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://physical-ai-humanoid-robotics-textb-tau.vercel.app/docs/module4-vla-robotics/introduction"><link data-rh="true" rel="alternate" href="https://physical-ai-humanoid-robotics-textb-tau.vercel.app/docs/module4-vla-robotics/introduction" hreflang="en"><link data-rh="true" rel="alternate" href="https://physical-ai-humanoid-robotics-textb-tau.vercel.app/docs/module4-vla-robotics/introduction" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Introduction to LLM-Driven Robotics","item":"https://physical-ai-humanoid-robotics-textb-tau.vercel.app/docs/module4-vla-robotics/introduction"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Atom Feed"><link rel="stylesheet" href="/assets/css/styles.87aa9449.css">
<script src="/assets/js/runtime~main.01f656c7.js" defer="defer"></script>
<script src="/assets/js/main.63dcfb86.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/module1-ros2/introduction">Tutorial</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module1-ros2/introduction"><span title="ROS 2 Nervous System" class="categoryLinkLabel_W154">ROS 2 Nervous System</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module2-digital-twins/01-introduction"><span title="Digital Twins (Gazebo + Unity)" class="categoryLinkLabel_W154">Digital Twins (Gazebo + Unity)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module3-nvidia-isaac-sim/01-introduction"><span title="NVIDIA Isaac Sim + VSLAM + Nav2" class="categoryLinkLabel_W154">NVIDIA Isaac Sim + VSLAM + Nav2</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/module4-vla-robotics/introduction"><span title="Vision-Language-Action (VLA) Robotics" class="categoryLinkLabel_W154">Vision-Language-Action (VLA) Robotics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/module4-vla-robotics/introduction"><span title="Introduction to LLM-Driven Robotics" class="linkLabel_WmDU">Introduction to LLM-Driven Robotics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module4-vla-robotics/whisper"><span title="Voice Commands with Whisper" class="linkLabel_WmDU">Voice Commands with Whisper</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module4-vla-robotics/action-graphs"><span title="Natural Language to Robotic Action Graphs" class="linkLabel_WmDU">Natural Language to Robotic Action Graphs</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module4-vla-robotics/cognitive-planners"><span title="Cognitive Planners for Complex Tasks" class="linkLabel_WmDU">Cognitive Planners for Complex Tasks</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module4-vla-robotics/breaking-down-language"><span title="Breaking Down Language: From Utterance to Robot Action" class="linkLabel_WmDU">Breaking Down Language: From Utterance to Robot Action</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module4-vla-robotics/ros2-integration"><span title="ROS 2 Integration for VLA Pipelines" class="linkLabel_WmDU">ROS 2 Integration for VLA Pipelines</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/module4-vla-robotics/diagrams/cognitive-planner-flow"><span title="diagrams" class="categoryLinkLabel_W154">diagrams</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/capstone-humanoid-robot/overview"><span title="Capstone - Autonomous Humanoid Robot" class="categoryLinkLabel_W154">Capstone - Autonomous Humanoid Robot</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro"><span title="**Physical AI &amp; Humanoid Robotics**" class="linkLabel_WmDU">**Physical AI &amp; Humanoid Robotics**</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Vision-Language-Action (VLA) Robotics</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Introduction to LLM-Driven Robotics</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div style="display:flex;justify-content:space-between"><div class="personalizationContainer_KDQQ"><button>Personalize Chapter for Me</button></div><div class="translatorContainer_PjNM"><button>Urdu Translation</button></div></div><div class="theme-doc-markdown markdown"><header><h1>Introduction to LLM-Driven Robotics</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-convergence-of-large-language-models-and-robotics">The Convergence of Large Language Models and Robotics<a href="#the-convergence-of-large-language-models-and-robotics" class="hash-link" aria-label="Direct link to The Convergence of Large Language Models and Robotics" title="Direct link to The Convergence of Large Language Models and Robotics" translate="no">​</a></h2>
<p>The field of robotics is undergoing a transformative shift with the integration of Large Language Models (LLMs). Traditionally, robots have been programmed with explicit instructions for specific tasks, limiting their adaptability and requiring extensive engineering effort for new scenarios. LLMs, with their unprecedented ability to understand, generate, and reason with human language, offer a new paradigm for robot control and intelligence. This convergence, often termed Vision-Language-Action (VLA) systems or LLM-driven robotics, aims to enable robots to interpret high-level natural language commands, reason about complex tasks, and translate these into a sequence of executable robotic actions.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="limitations-of-traditional-robotics">Limitations of Traditional Robotics:<a href="#limitations-of-traditional-robotics" class="hash-link" aria-label="Direct link to Limitations of Traditional Robotics:" title="Direct link to Limitations of Traditional Robotics:" translate="no">​</a></h3>
<ul>
<li class=""><strong>Rigid Programming:</strong> Robots follow predefined scripts, lacking flexibility for novel situations.</li>
<li class=""><strong>Complex Task Decomposition:</strong> Breaking down high-level human goals into low-level robot actions is a laborious manual process.</li>
<li class=""><strong>Limited Human-Robot Interaction:</strong> Communication is often confined to predefined commands or graphical user interfaces.</li>
<li class=""><strong>Lack of Generalization:</strong> Solutions are often domain-specific and do not easily transfer to new environments or tasks.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-llms-for-robotics">Why LLMs for Robotics?<a href="#why-llms-for-robotics" class="hash-link" aria-label="Direct link to Why LLMs for Robotics?" title="Direct link to Why LLMs for Robotics?" translate="no">​</a></h2>
<p>LLMs bring several powerful capabilities to robotics that address the limitations of traditional approaches:</p>
<ol>
<li class=""><strong>Natural Language Understanding (NLU):</strong> Robots can now understand nuanced human instructions, requests, and questions, moving beyond keyword recognition to contextual comprehension.</li>
<li class=""><strong>Task Planning and Decomposition:</strong> LLMs can take a high-level goal (e.g., &quot;make me a cup of coffee&quot;) and break it down into a logical sequence of sub-tasks and actions, leveraging their vast knowledge base.</li>
<li class=""><strong>Reasoning and Common Sense:</strong> LLMs possess a form of common-sense reasoning derived from their training data, allowing robots to infer unstated intentions, handle ambiguities, and adapt to unexpected situations.</li>
<li class=""><strong>Learning from Instructions:</strong> Robots can learn new tasks or refine existing ones through natural language explanations, rather than needing explicit reprogramming.</li>
<li class=""><strong>Human-Robot Collaboration:</strong> Facilitates more intuitive and natural interaction, allowing humans to collaborate with robots using everyday language.</li>
<li class=""><strong>Error Recovery and Explanations:</strong> LLMs can help robots understand why a task failed, suggest recovery strategies, and even explain their actions in natural language.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="vision-language-action-vla-systems">Vision-Language-Action (VLA) Systems<a href="#vision-language-action-vla-systems" class="hash-link" aria-label="Direct link to Vision-Language-Action (VLA) Systems" title="Direct link to Vision-Language-Action (VLA) Systems" translate="no">​</a></h2>
<p>VLA systems represent a holistic approach where robots integrate visual perception with language understanding to perform physical actions. The core idea is that an LLM acts as the &quot;brain,&quot; interpreting the user&#x27;s intent and orchestrating the robot&#x27;s interactions with the world based on what it &quot;sees&quot; and what it &quot;knows.&quot;</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="architecture-overview-conceptual">Architecture Overview (Conceptual):<a href="#architecture-overview-conceptual" class="hash-link" aria-label="Direct link to Architecture Overview (Conceptual):" title="Direct link to Architecture Overview (Conceptual):" translate="no">​</a></h3>
<ul>
<li class=""><strong>Perception Module:</strong> Gathers information from the environment using cameras (RGB, depth), LiDAR, etc. This raw data is often processed into a symbolic representation or embedded vectors.</li>
<li class=""><strong>Language Understanding Module (LLM):</strong> Receives natural language instructions from a human. It processes these instructions, reasons about the task, and generates a plan or a sequence of high-level actions.</li>
<li class=""><strong>Action Generation/Execution Module:</strong> Translates the LLM&#x27;s high-level plan into low-level robot commands (e.g., joint movements, navigation goals, grasping primitives). This module interacts directly with the robot&#x27;s hardware and control systems.</li>
<li class=""><strong>Feedback Loop:</strong> Sensor feedback from the environment is continuously fed back into the system to monitor progress, detect errors, and update the LLM&#x27;s understanding of the current state.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="challenges-and-future-directions">Challenges and Future Directions<a href="#challenges-and-future-directions" class="hash-link" aria-label="Direct link to Challenges and Future Directions" title="Direct link to Challenges and Future Directions" translate="no">​</a></h2>
<p>While LLM-driven robotics holds immense promise, several challenges remain:</p>
<ul>
<li class=""><strong>Grounding:</strong> Ensuring the LLM&#x27;s abstract language understanding is accurately mapped to the physical world and the robot&#x27;s capabilities.</li>
<li class=""><strong>Safety and Reliability:</strong> Guaranteeing that LLM-generated plans are safe, robust, and do not lead to unintended consequences in real-world scenarios.</li>
<li class=""><strong>Computational Efficiency:</strong> Running complex LLMs in real-time on robotic platforms, especially those with limited computational resources.</li>
<li class=""><strong>Data Scarcity:</strong> Collecting diverse and comprehensive datasets for training LLMs specifically for robotic tasks.</li>
<li class=""><strong>Explainability:</strong> Making the LLM&#x27;s decision-making process transparent and understandable to humans.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h2>
<p>LLM-driven robotics is poised to revolutionize how we interact with and deploy robots. By empowering robots with natural language understanding, reasoning, and planning capabilities, we can unlock new levels of autonomy, flexibility, and human-robot collaboration. This chapter will delve into the specific components and techniques that make VLA systems possible, from voice command processing to cognitive planners and seamless ROS 2 integration.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module4-vla-robotics/01-introduction.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/module3-nvidia-isaac-sim/diagrams/vslam-pipeline"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">vslam-pipeline</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/module4-vla-robotics/whisper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Voice Commands with Whisper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#the-convergence-of-large-language-models-and-robotics" class="table-of-contents__link toc-highlight">The Convergence of Large Language Models and Robotics</a><ul><li><a href="#limitations-of-traditional-robotics" class="table-of-contents__link toc-highlight">Limitations of Traditional Robotics:</a></li></ul></li><li><a href="#why-llms-for-robotics" class="table-of-contents__link toc-highlight">Why LLMs for Robotics?</a></li><li><a href="#vision-language-action-vla-systems" class="table-of-contents__link toc-highlight">Vision-Language-Action (VLA) Systems</a><ul><li><a href="#architecture-overview-conceptual" class="table-of-contents__link toc-highlight">Architecture Overview (Conceptual):</a></li></ul></li><li><a href="#challenges-and-future-directions" class="table-of-contents__link toc-highlight">Challenges and Future Directions</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>