<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-capstone-humanoid-robot/object-detection" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Object Detection with Computer Vision | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://hasnainxdev.github.io/physical_ai_humanoid_robotics_textbook/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://hasnainxdev.github.io/physical_ai_humanoid_robotics_textbook/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://hasnainxdev.github.io/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/object-detection"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Object Detection with Computer Vision | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="The Robot&#x27;s Eyes: Perceiving the World"><meta data-rh="true" property="og:description" content="The Robot&#x27;s Eyes: Perceiving the World"><link data-rh="true" rel="icon" href="/physical_ai_humanoid_robotics_textbook/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://hasnainxdev.github.io/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/object-detection"><link data-rh="true" rel="alternate" href="https://hasnainxdev.github.io/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/object-detection" hreflang="en"><link data-rh="true" rel="alternate" href="https://hasnainxdev.github.io/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/object-detection" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Object Detection with Computer Vision","item":"https://hasnainxdev.github.io/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/object-detection"}]}</script><link rel="alternate" type="application/rss+xml" href="/physical_ai_humanoid_robotics_textbook/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/physical_ai_humanoid_robotics_textbook/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Atom Feed"><link rel="stylesheet" href="/physical_ai_humanoid_robotics_textbook/assets/css/styles.87aa9449.css">
<script src="/physical_ai_humanoid_robotics_textbook/assets/js/runtime~main.dbac8fcf.js" defer="defer"></script>
<script src="/physical_ai_humanoid_robotics_textbook/assets/js/main.664de88e.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/physical_ai_humanoid_robotics_textbook/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/physical_ai_humanoid_robotics_textbook/"><div class="navbar__logo"><img src="/physical_ai_humanoid_robotics_textbook/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/physical_ai_humanoid_robotics_textbook/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/physical_ai_humanoid_robotics_textbook/docs/module1-ros2/introduction">Tutorial</a><a class="navbar__item navbar__link" href="/physical_ai_humanoid_robotics_textbook/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical_ai_humanoid_robotics_textbook/docs/module1-ros2/introduction"><span title="ROS 2 Nervous System" class="categoryLinkLabel_W154">ROS 2 Nervous System</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical_ai_humanoid_robotics_textbook/docs/module2-digital-twins/01-introduction"><span title="Digital Twins (Gazebo + Unity)" class="categoryLinkLabel_W154">Digital Twins (Gazebo + Unity)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical_ai_humanoid_robotics_textbook/docs/module3-nvidia-isaac-sim/01-introduction"><span title="NVIDIA Isaac Sim + VSLAM + Nav2" class="categoryLinkLabel_W154">NVIDIA Isaac Sim + VSLAM + Nav2</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical_ai_humanoid_robotics_textbook/docs/module4-vla-robotics/introduction"><span title="Vision-Language-Action (VLA) Robotics" class="categoryLinkLabel_W154">Vision-Language-Action (VLA) Robotics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/overview"><span title="Capstone - Autonomous Humanoid Robot" class="categoryLinkLabel_W154">Capstone - Autonomous Humanoid Robot</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/overview"><span title="Capstone Project Overview: Autonomous Humanoid Robot" class="linkLabel_WmDU">Capstone Project Overview: Autonomous Humanoid Robot</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/voice-llm-integration"><span title="Integrating Voice Commands &amp; LLMs" class="linkLabel_WmDU">Integrating Voice Commands &amp; LLMs</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/slam-nav2"><span title="SLAM &amp; Nav2 for Autonomous Navigation" class="linkLabel_WmDU">SLAM &amp; Nav2 for Autonomous Navigation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/object-detection"><span title="Object Detection with Computer Vision" class="linkLabel_WmDU">Object Detection with Computer Vision</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/object-manipulation"><span title="Object Manipulation with ROS Control" class="linkLabel_WmDU">Object Manipulation with ROS Control</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/full-task-execution"><span title="Full Task Execution in Simulation" class="linkLabel_WmDU">Full Task Execution in Simulation</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/physical_ai_humanoid_robotics_textbook/docs/intro"><span title="**Physical AI &amp; Humanoid Robotics**" class="linkLabel_WmDU">**Physical AI &amp; Humanoid Robotics**</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/physical_ai_humanoid_robotics_textbook/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Capstone - Autonomous Humanoid Robot</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Object Detection with Computer Vision</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div style="display:flex;justify-content:space-between"><div class="personalizationContainer_KDQQ"><button>Personalize Chapter for Me</button></div><div class="translatorContainer_PjNM"><button>Urdu Translation</button></div></div><div class="theme-doc-markdown markdown"><header><h1>Object Detection with Computer Vision</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-robots-eyes-perceiving-the-world">The Robot&#x27;s Eyes: Perceiving the World<a href="#the-robots-eyes-perceiving-the-world" class="hash-link" aria-label="Direct link to The Robot&#x27;s Eyes: Perceiving the World" title="Direct link to The Robot&#x27;s Eyes: Perceiving the World" translate="no">​</a></h2>
<p>For an autonomous humanoid robot to interact intelligently with its environment in the Capstone Project, it must possess robust visual perception capabilities, particularly object detection. Object detection allows the robot to identify and locate specific items within its field of view, providing crucial information for manipulation tasks, navigation decisions, and understanding human commands. This chapter delves into the application of modern computer vision techniques for object detection, specifically tailored for integration within our simulated humanoid system.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="fundamentals-of-object-detection">Fundamentals of Object Detection<a href="#fundamentals-of-object-detection" class="hash-link" aria-label="Direct link to Fundamentals of Object Detection" title="Direct link to Fundamentals of Object Detection" translate="no">​</a></h2>
<p>Object detection is a computer vision task that involves two primary goals:</p>
<ol>
<li class=""><strong>Classification:</strong> Identifying what objects are present in an image (e.g., &quot;Is there a chair?&quot;).</li>
<li class=""><strong>Localization:</strong> Determining the precise location of each identified object within the image, typically represented by a bounding box (e.g., &quot;The chair is at pixels x1, y1, x2, y2&quot;).</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="evolution-of-object-detection-models">Evolution of Object Detection Models:<a href="#evolution-of-object-detection-models" class="hash-link" aria-label="Direct link to Evolution of Object Detection Models:" title="Direct link to Evolution of Object Detection Models:" translate="no">​</a></h3>
<ul>
<li class=""><strong>Traditional Methods:</strong> Early approaches like Haar Cascades and HOG features were limited but foundational.</li>
<li class=""><strong>Two-Stage Detectors:</strong> Models like R-CNN, Fast R-CNN, and Faster R-CNN achieve high accuracy by first proposing regions of interest and then classifying/refining them.</li>
<li class=""><strong>One-Stage Detectors:</strong> Models like YOLO (You Only Look Once) and SSD (Single Shot MultiBox Detector) prioritize speed by performing detection in a single pass, making them suitable for real-time robotic applications.</li>
<li class=""><strong>Transformer-based Models:</strong> More recent architectures like DETR leverage Transformers for end-to-end detection, often simplifying the pipeline.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="deep-learning-for-object-detection">Deep Learning for Object Detection<a href="#deep-learning-for-object-detection" class="hash-link" aria-label="Direct link to Deep Learning for Object Detection" title="Direct link to Deep Learning for Object Detection" translate="no">​</a></h2>
<p>Modern object detection heavily relies on deep convolutional neural networks (CNNs) due to their ability to learn rich, hierarchical features from image data. For our Capstone Project, one-stage detectors or efficient two-stage detectors are generally preferred for real-time performance on robotic platforms.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-components-of-a-dnn-based-detector">Key Components of a DNN-based Detector:<a href="#key-components-of-a-dnn-based-detector" class="hash-link" aria-label="Direct link to Key Components of a DNN-based Detector:" title="Direct link to Key Components of a DNN-based Detector:" translate="no">​</a></h3>
<ul>
<li class=""><strong>Backbone Network:</strong> A pre-trained CNN (e.g., ResNet, MobileNet) that extracts features from the input image.</li>
<li class=""><strong>Neck:</strong> Connects the backbone to the detection heads, often involving feature pyramid networks (FPNs) to fuse features at different scales.</li>
<li class=""><strong>Detection Head(s):</strong> Predicts bounding box coordinates and class probabilities for each detected object.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="integrating-object-detection-in-isaac-sim">Integrating Object Detection in Isaac Sim<a href="#integrating-object-detection-in-isaac-sim" class="hash-link" aria-label="Direct link to Integrating Object Detection in Isaac Sim" title="Direct link to Integrating Object Detection in Isaac Sim" translate="no">​</a></h2>
<p>NVIDIA Isaac Sim provides an excellent environment for simulating camera sensors and integrating object detection pipelines. Synthetic data generation (as discussed in Module 3) is particularly valuable for training these models.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="simulation-setup">Simulation Setup:<a href="#simulation-setup" class="hash-link" aria-label="Direct link to Simulation Setup:" title="Direct link to Simulation Setup:" translate="no">​</a></h3>
<ol>
<li class=""><strong>Simulated Camera:</strong> Attach high-resolution RGB cameras to the humanoid robot model in Isaac Sim.</li>
<li class=""><strong>Dataset Generation:</strong> Utilize Isaac Sim&#x27;s Synthetic Data Generation (SDG) capabilities to generate a large dataset of images with automatically annotated bounding boxes and segmentation masks for the objects the robot needs to detect.</li>
<li class=""><strong>Domain Randomization:</strong> Apply domain randomization techniques during SDG to ensure the trained model generalizes well to variations in lighting, textures, and object poses.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="ros-2-integration-for-object-detection">ROS 2 Integration for Object Detection:<a href="#ros-2-integration-for-object-detection" class="hash-link" aria-label="Direct link to ROS 2 Integration for Object Detection:" title="Direct link to ROS 2 Integration for Object Detection:" translate="no">​</a></h3>
<ol>
<li class=""><strong>Camera Node:</strong> The Isaac Sim ROS 2 bridge publishes simulated camera images to a ROS 2 topic (e.g., <code>/rgb_camera/image_raw</code>).</li>
<li class=""><strong>Object Detection Node:</strong> A dedicated ROS 2 node subscribes to the camera image topic. This node runs the chosen object detection model (e.g., YOLOv8, a custom trained model) and publishes the detection results.<!-- -->
<ul>
<li class=""><strong>Input:</strong> <code>sensor_msgs/Image</code></li>
<li class=""><strong>Output:</strong> <code>vision_msgs/Detection2DArray</code> (or a custom message containing bounding boxes, class IDs, and confidence scores).</li>
</ul>
</li>
<li class=""><strong>Visualization Node (Optional):</strong> Another ROS 2 node can subscribe to the detection results and overlay bounding boxes on the image stream for debugging and visualization in RViz.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="example-workflow-detecting-a-coffee-cup">Example Workflow: Detecting a &quot;Coffee Cup&quot;<a href="#example-workflow-detecting-a-coffee-cup" class="hash-link" aria-label="Direct link to Example Workflow: Detecting a &quot;Coffee Cup&quot;" title="Direct link to Example Workflow: Detecting a &quot;Coffee Cup&quot;" translate="no">​</a></h2>
<p>Consider the Capstone task: &quot;Find the coffee cup and bring it to me.&quot;</p>
<ol>
<li class=""><strong>LLM Command:</strong> The cognitive planner (LLM) receives the instruction and breaks it down into <code>find(coffee_cup)</code>.</li>
<li class=""><strong>Robot Action:</strong> The LLM instructs the robot&#x27;s navigation system to move towards areas where coffee cups might be found (e.g., kitchen counter, office desk).</li>
<li class=""><strong>Camera Input:</strong> As the robot navigates, its simulated camera streams images.</li>
<li class=""><strong>Object Detection Node:</strong> The detection node processes these images. If a &quot;coffee cup&quot; is detected:<!-- -->
<ul>
<li class="">It publishes a <code>Detection2DArray</code> message containing the bounding box and confidence score for the coffee cup.</li>
<li class="">It can also estimate the 3D pose of the cup using depth information (from a depth camera or stereo vision) or by leveraging a trained 3D object pose estimation model.</li>
</ul>
</li>
<li class=""><strong>LLM Update:</strong> The LLM planner receives the object detection information, confirms the <code>coffee_cup</code>&#x27;s presence and location, and updates its internal world model. This then triggers the next phase of the task, such as <code>grasp(coffee_cup)</code>.</li>
</ol>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h2>
<p>Object detection with computer vision is a vital component of the Capstone Project, providing the humanoid robot with the ability to &quot;see&quot; and understand its physical environment. By integrating robust DNN-based detection models within the Isaac Sim and ROS 2 framework, we empower the robot to identify and locate objects critical for performing complex manipulation tasks and fulfilling natural language commands, bridging the gap between perception and intelligent action.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/capstone-humanoid-robot/04-object-detection.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/slam-nav2"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">SLAM &amp; Nav2 for Autonomous Navigation</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/physical_ai_humanoid_robotics_textbook/docs/capstone-humanoid-robot/object-manipulation"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Object Manipulation with ROS Control</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#the-robots-eyes-perceiving-the-world" class="table-of-contents__link toc-highlight">The Robot&#39;s Eyes: Perceiving the World</a></li><li><a href="#fundamentals-of-object-detection" class="table-of-contents__link toc-highlight">Fundamentals of Object Detection</a><ul><li><a href="#evolution-of-object-detection-models" class="table-of-contents__link toc-highlight">Evolution of Object Detection Models:</a></li></ul></li><li><a href="#deep-learning-for-object-detection" class="table-of-contents__link toc-highlight">Deep Learning for Object Detection</a><ul><li><a href="#key-components-of-a-dnn-based-detector" class="table-of-contents__link toc-highlight">Key Components of a DNN-based Detector:</a></li></ul></li><li><a href="#integrating-object-detection-in-isaac-sim" class="table-of-contents__link toc-highlight">Integrating Object Detection in Isaac Sim</a><ul><li><a href="#simulation-setup" class="table-of-contents__link toc-highlight">Simulation Setup:</a></li><li><a href="#ros-2-integration-for-object-detection" class="table-of-contents__link toc-highlight">ROS 2 Integration for Object Detection:</a></li></ul></li><li><a href="#example-workflow-detecting-a-coffee-cup" class="table-of-contents__link toc-highlight">Example Workflow: Detecting a &quot;Coffee Cup&quot;</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/physical_ai_humanoid_robotics_textbook/docs/intro">Tutorial</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/physical_ai_humanoid_robotics_textbook/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>