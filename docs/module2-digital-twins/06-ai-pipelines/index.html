<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module2-digital-twins/06-ai-pipelines" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Connecting Sensor Outputs to AI Pipelines | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://physical-ai-humanoid-robotics-textb-tau.vercel.app/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://physical-ai-humanoid-robotics-textb-tau.vercel.app/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://physical-ai-humanoid-robotics-textb-tau.vercel.app/docs/module2-digital-twins/06-ai-pipelines"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Connecting Sensor Outputs to AI Pipelines | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="1. From Raw Data to Actionable Insights"><meta data-rh="true" property="og:description" content="1. From Raw Data to Actionable Insights"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://physical-ai-humanoid-robotics-textb-tau.vercel.app/docs/module2-digital-twins/06-ai-pipelines"><link data-rh="true" rel="alternate" href="https://physical-ai-humanoid-robotics-textb-tau.vercel.app/docs/module2-digital-twins/06-ai-pipelines" hreflang="en"><link data-rh="true" rel="alternate" href="https://physical-ai-humanoid-robotics-textb-tau.vercel.app/docs/module2-digital-twins/06-ai-pipelines" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AI Pipelines","item":"https://physical-ai-humanoid-robotics-textb-tau.vercel.app/docs/module2-digital-twins/06-ai-pipelines"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Atom Feed"><link rel="stylesheet" href="/assets/css/styles.87aa9449.css">
<script src="/assets/js/runtime~main.01f656c7.js" defer="defer"></script>
<script src="/assets/js/main.d97914f4.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/module1-ros2/introduction">Tutorial</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module1-ros2/introduction"><span title="ROS 2 Nervous System" class="categoryLinkLabel_W154">ROS 2 Nervous System</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/module2-digital-twins/01-introduction"><span title="Digital Twins (Gazebo + Unity)" class="categoryLinkLabel_W154">Digital Twins (Gazebo + Unity)</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module2-digital-twins/01-introduction"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module2-digital-twins/02-gazebo-simulation"><span title="Gazebo Simulation" class="linkLabel_WmDU">Gazebo Simulation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module2-digital-twins/03-physics-concepts"><span title="Physics Concepts" class="linkLabel_WmDU">Physics Concepts</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module2-digital-twins/04-unity-rendering"><span title="Unity Rendering" class="linkLabel_WmDU">Unity Rendering</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module2-digital-twins/05-sensor-simulation"><span title="Sensor Simulation" class="linkLabel_WmDU">Sensor Simulation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/module2-digital-twins/06-ai-pipelines"><span title="AI Pipelines" class="linkLabel_WmDU">AI Pipelines</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module3-nvidia-isaac-sim/01-introduction"><span title="NVIDIA Isaac Sim + VSLAM + Nav2" class="categoryLinkLabel_W154">NVIDIA Isaac Sim + VSLAM + Nav2</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module4-vla-robotics/introduction"><span title="Vision-Language-Action (VLA) Robotics" class="categoryLinkLabel_W154">Vision-Language-Action (VLA) Robotics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/capstone-humanoid-robot/overview"><span title="Capstone - Autonomous Humanoid Robot" class="categoryLinkLabel_W154">Capstone - Autonomous Humanoid Robot</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro"><span title="**Physical AI &amp; Humanoid Robotics**" class="linkLabel_WmDU">**Physical AI &amp; Humanoid Robotics**</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Digital Twins (Gazebo + Unity)</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">AI Pipelines</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div style="display:flex;justify-content:space-between"><div class="personalizationContainer_KDQQ"><button>Personalize Chapter for Me</button></div><div class="translatorContainer_PjNM"><button>Urdu Translation</button></div></div><div class="theme-doc-markdown markdown"><header><h1>Connecting Sensor Outputs to AI Pipelines</h1></header><h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-from-raw-data-to-actionable-insights">1. From Raw Data to Actionable Insights<a href="#1-from-raw-data-to-actionable-insights" class="hash-link" aria-label="Direct link to 1. From Raw Data to Actionable Insights" title="Direct link to 1. From Raw Data to Actionable Insights" translate="no">â€‹</a></h2>
<p>Having a digital twin that produces realistic sensor data is the first step. The next, and more critical, step is to process this stream of data and turn it into information that an AI agent can use to make decisions. This process is often called an <strong>AI pipeline</strong> or a <strong>perception pipeline</strong>.</p>
<p>The pipeline is a series of nodes, each responsible for a specific processing task. The output of one node becomes the input of the next, creating a flow of information from raw sensor readings to high-level understanding.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-typical-ai-pipeline">A Typical AI Pipeline<a href="#a-typical-ai-pipeline" class="hash-link" aria-label="Direct link to A Typical AI Pipeline" title="Direct link to A Typical AI Pipeline" translate="no">â€‹</a></h3>
<!-- -->
<p>In this example, raw data from simulated sensors (camera, LiDAR, IMU) is published to ROS 2 topics. A set of perception nodes subscribes to these topics, processes the data, and publishes higher-level information (detected objects, obstacles, robot pose). Finally, the AI agent uses this processed information to make a decision and send a command to the robot&#x27;s controllers.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-example-an-object-detection-pipeline">2. Example: An Object Detection Pipeline<a href="#2-example-an-object-detection-pipeline" class="hash-link" aria-label="Direct link to 2. Example: An Object Detection Pipeline" title="Direct link to 2. Example: An Object Detection Pipeline" translate="no">â€‹</a></h2>
<p>Let&#x27;s walk through a concrete example: using a simulated camera to detect objects.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-1-the-simulator-data-source">Step 1: The Simulator (Data Source)<a href="#step-1-the-simulator-data-source" class="hash-link" aria-label="Direct link to Step 1: The Simulator (Data Source)" title="Direct link to Step 1: The Simulator (Data Source)" translate="no">â€‹</a></h3>
<ul>
<li class=""><strong>Simulator</strong>: Unity or Gazebo.</li>
<li class=""><strong>Sensor</strong>: A simulated camera attached to the humanoid&#x27;s head.</li>
<li class=""><strong>Action</strong>: The simulator&#x27;s ROS 2 plugin renders the scene from the camera&#x27;s viewpoint and publishes the resulting image to the <code>/camera/image_raw</code> topic as a <code>sensor_msgs/Image</code> message. This happens at a regular rate, for example, 30 times per second (30 Hz).</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-2-the-ai-node-processing">Step 2: The AI Node (Processing)<a href="#step-2-the-ai-node-processing" class="hash-link" aria-label="Direct link to Step 2: The AI Node (Processing)" title="Direct link to Step 2: The AI Node (Processing)" translate="no">â€‹</a></h3>
<ul>
<li class=""><strong>Node</strong>: An object detection node, likely written in Python using a deep learning framework like TensorFlow or PyTorch.</li>
<li class=""><strong>Subscription</strong>: The node subscribes to the <code>/camera/image_raw</code> topic.</li>
<li class=""><strong>Core Logic</strong>:<!-- -->
<ol>
<li class=""><strong>Callback</strong>: Whenever a new image message is received, the node&#x27;s callback function is triggered.</li>
<li class=""><strong>Conversion</strong>: The ROS 2 <code>Image</code> message is converted into a format that the deep learning model can understand (e.g., a NumPy array or a PyTorch tensor). Libraries like <code>cv_bridge</code> are commonly used for this.</li>
<li class=""><strong>Inference</strong>: The image is passed through a pre-trained object detection model (e.g., YOLO, SSD, Faster R-CNN).</li>
<li class=""><strong>Result</strong>: The model outputs a list of detected objects, each with a class label (e.g., &quot;cup,&quot; &quot;book&quot;), a confidence score, and a bounding box.</li>
</ol>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-3-the-output-actionable-information">Step 3: The Output (Actionable Information)<a href="#step-3-the-output-actionable-information" class="hash-link" aria-label="Direct link to Step 3: The Output (Actionable Information)" title="Direct link to Step 3: The Output (Actionable Information)" translate="no">â€‹</a></h3>
<ul>
<li class=""><strong>Publication</strong>: The object detection node publishes the results to a new topic, for example, <code>/objects/detected</code>.</li>
<li class=""><strong>Message Type</strong>: The message type should be structured to hold the detection information. ROS 2 has a standard message type for this: <code>vision_msgs/Detection3DArray</code>, which can store the object&#x27;s identity, position, and size.</li>
<li class=""><strong>Downstream Consumer</strong>: The AI planner or a specific task-oriented node (e.g., a &quot;grasping&quot; node) can now subscribe to <code>/objects/detected</code>. It no longer needs to worry about the raw pixels; it can work directly with the high-level information: &quot;There is a cup at position (x, y, z).&quot;</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-this-decoupling-is-powerful">Why This Decoupling is Powerful<a href="#why-this-decoupling-is-powerful" class="hash-link" aria-label="Direct link to Why This Decoupling is Powerful" title="Direct link to Why This Decoupling is Powerful" translate="no">â€‹</a></h3>
<ul>
<li class=""><strong>Modularity</strong>: The object detection node is a self-contained component. You can swap out the AI model (e.g., upgrade from YOLOv5 to YOLOv8) without changing any other part of the system.</li>
<li class=""><strong>Reusability</strong>: You can use the same object detection node with a real camera by simply remapping the input topic. The node doesn&#x27;t care if the image comes from a simulator or a physical device.</li>
<li class=""><strong>Efficiency</strong>: Raw sensor data, especially from cameras and LiDAR, can have a very high bandwidth. By processing it close to the source and publishing only the high-level results, you reduce the overall data load on the ROS 2 network.</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-integrating-state-estimation">3. Integrating State Estimation<a href="#3-integrating-state-estimation" class="hash-link" aria-label="Direct link to 3. Integrating State Estimation" title="Direct link to 3. Integrating State Estimation" translate="no">â€‹</a></h2>
<p>While detecting external objects is crucial, the robot also needs to know its own stateâ€”its position, orientation, and velocity. This is the job of a <strong>state estimator</strong>.</p>
<ul>
<li class=""><strong>Inputs</strong>: The state estimator typically fuses data from multiple sensors, most commonly an <strong>IMU</strong> (for orientation and acceleration) and <strong>wheel odometry</strong> (for movement tracking, if the robot has wheels) or <strong>leg kinematics</strong> (for humanoids).</li>
<li class=""><strong>Algorithm</strong>: It uses a filtering algorithm, like an <strong>Extended Kalman Filter (EKF)</strong> or an <strong>Unscented Kalman Filter (UKF)</strong>, to combine these noisy and incomplete sensor readings into a single, more accurate estimate of the robot&#x27;s state.</li>
<li class=""><strong>Output</strong>: The estimator publishes the robot&#x27;s state to a topic like <code>/odometry/filtered</code> using the <code>nav_msgs/Odometry</code> message type.</li>
<li class=""><strong>Importance</strong>: Nearly every other AI task, from navigation to manipulation, depends on having an accurate estimate of the robot&#x27;s own pose. Your AI needs to know &quot;Where am I?&quot; before it can decide &quot;What should I do?&quot;.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">â€‹</a></h2>
<p>Connecting sensor outputs to AI pipelines is the essence of building an intelligent robot. By using the ROS 2 publisher/subscriber model, you can create modular, decoupled pipelines that transform raw, high-bandwidth sensor data from your digital twin into the high-level, actionable insights needed by your AI agents. This architecture is fundamental to creating a robust and scalable robotics software system.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module2-digital-twins/06-ai-pipelines.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/module2-digital-twins/05-sensor-simulation"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Sensor Simulation</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/module3-nvidia-isaac-sim/01-introduction"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Introduction</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-from-raw-data-to-actionable-insights" class="table-of-contents__link toc-highlight">1. From Raw Data to Actionable Insights</a><ul><li><a href="#a-typical-ai-pipeline" class="table-of-contents__link toc-highlight">A Typical AI Pipeline</a></li></ul></li><li><a href="#2-example-an-object-detection-pipeline" class="table-of-contents__link toc-highlight">2. Example: An Object Detection Pipeline</a><ul><li><a href="#step-1-the-simulator-data-source" class="table-of-contents__link toc-highlight">Step 1: The Simulator (Data Source)</a></li><li><a href="#step-2-the-ai-node-processing" class="table-of-contents__link toc-highlight">Step 2: The AI Node (Processing)</a></li><li><a href="#step-3-the-output-actionable-information" class="table-of-contents__link toc-highlight">Step 3: The Output (Actionable Information)</a></li><li><a href="#why-this-decoupling-is-powerful" class="table-of-contents__link toc-highlight">Why This Decoupling is Powerful</a></li></ul></li><li><a href="#3-integrating-state-estimation" class="table-of-contents__link toc-highlight">3. Integrating State Estimation</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://x.com/hasnainxdev" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/hasnainxdev" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2025 Physical AI & Humanoid Robotics. Built with ðŸ’– Muhammad Hasnain</div></div></div></footer></div>
</body>
</html>